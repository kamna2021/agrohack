{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip3 install torch==1.10.0+cu113 torchvision==0.11.1+cu113  -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "!pip install albumentations\n",
    "!pip install pandas \n",
    "!pip install tqdm \n",
    "!pip install opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2 \n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "import torch.nn.functional as F\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "LR = 1e-4\n",
    "SPLIT = 0.2\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = \"cpu\"\n",
    "print(DEVICE)\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "DATAPATH = Path.cwd()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем информацию о датасете\n",
    "def png2jpg(path):\n",
    "    print(path)\n",
    "    im = Image.open(path)\n",
    "    rgb_im = im.convert('RGB')\n",
    "    rgb_im.save(path.split(\".\")[0]+\".jpg\")\n",
    "    os.remove(path)\n",
    "\n",
    "def create_df_from_dataset(directory):\n",
    "    base_dir = Path.cwd() / Path(directory) \n",
    "    annot_file = base_dir / Path('annotations.xml')\n",
    "    tree = ET.parse(annot_file)\n",
    "    root = tree.getroot()\n",
    "    images = root.findall('image')\n",
    "    image_id = []\n",
    "    image_width = []\n",
    "    image_height = []\n",
    "    image_coords = []\n",
    "    s_image_coords = []\n",
    "    image_bboxes = []\n",
    "    for image in images:\n",
    "        img_name = image.attrib.get('name',\"\")\n",
    "        if (img_name.split(\".\")[1] == \"png\"):\n",
    "            continue\n",
    "            if (os.path.isfile(str(Path.cwd() / 'dataset' / img_name))):\n",
    "                png2jpg(str(Path.cwd() / directory / img_name))\n",
    "            img_name = img_name.split(\".\")[0] + \".jpg\"\n",
    "        image_id.append(img_name)\n",
    "        i_width = float(image.attrib.get('width',0))\n",
    "        i_height = float(image.attrib.get('height',0))\n",
    "        image_width.append(i_width)\n",
    "        image_height.append(i_height)\n",
    "        points = image.findall('points')\n",
    "        boxes = []\n",
    "        if len(points) == 0:\n",
    "            image_coords.append(\"\")\n",
    "        else:\n",
    "            for point in points:\n",
    "                coords = point.attrib.get('points',\"\") + \";\"\n",
    "                for coord in coords.split(\";\"):\n",
    "                    if coord != '':\n",
    "                        coord = coord.split(\",\")\n",
    "                        x = float(coord[0])\n",
    "                        y = float(coord[1])\n",
    "                        xmin = x - 0.98*i_width if x - 0.98*i_width >= 0 else 0\n",
    "                        ymin = y - 0.98*i_height if y - 0.98*i_height >=0 else 0\n",
    "                        width = xmin + 0.04*i_width if xmin + 0.04*i_width <= i_width else i_width\n",
    "                        height = ymin + 0.04*i_height if xmin + 0.04*i_height <= i_height else i_height\n",
    "                        boxes.append([xmin, ymin, width, height])\n",
    "        image_bboxes.append(boxes)\n",
    "    df = pd.DataFrame({\n",
    "        \"image_id\": image_id,\n",
    "        \"width\": image_width,\n",
    "        \"height\": image_height,\n",
    "        \"bboxes\": image_bboxes,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "df = create_df_from_dataset(\"dataset\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask = df[df[\"bboxes\"].apply(lambda x: x != [])] \n",
    "df_unmask = df[df[\"bboxes\"].apply(lambda x: x == [])] \n",
    "# df_mask\n",
    "# df_unmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataFrame,split):\n",
    "    len_tot = len(dataFrame)\n",
    "    val_len = int(split*len_tot)\n",
    "    train_len = len_tot-val_len\n",
    "    train_data,val_data = dataFrame.iloc[:train_len][:],dataFrame.iloc[train_len:][:]\n",
    "    return train_data,val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df,val_data_df = train_test_split(df_mask,SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CeedDataset(Dataset):\n",
    "    def __init__(self,data,root_dir,transform=None,train=True):\n",
    "        self.data = data\n",
    "        self.root_dir = root_dir\n",
    "        self.image_names = self.data.image_id.values\n",
    "        self.bboxes = self.data.bboxes.values\n",
    "        self.transform = transform\n",
    "        self.isTrain = train\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,index):\n",
    "        img_path = str(Path(os.path.join(self.root_dir,self.image_names[index])))\n",
    "        print(img_path)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        bboxes = torch.tensor(self.bboxes[index],dtype=torch.float64)\n",
    "        bboxes[:,2] = bboxes[:,0]+bboxes[:,2]\n",
    "        bboxes[:,3] = bboxes[:,1]+bboxes[:,3]\n",
    "        area = (bboxes[:,3]-bboxes[:,1])*(bboxes[:,2]-bboxes[:,0])\n",
    "        area = torch.as_tensor(area,dtype=torch.float32)\n",
    "        labels = torch.ones((len(bboxes),),dtype=torch.int64)\n",
    "        iscrowd = torch.zeros((len(bboxes),),dtype=torch.int64)\n",
    "        target = {}\n",
    "        target['boxes'] = bboxes\n",
    "        target['labels']= labels\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "        target[\"area\"] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "        if self.transform is not None:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transform(**sample)\n",
    "            image = sample['image']\n",
    "            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "        return image,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Flip(0.5),\n",
    "    ToTensorV2(p=1.0)\n",
    "],bbox_params = {'format':\"pascal_voc\",'label_fields': ['labels']})\n",
    "val_transform = A.Compose([\n",
    "      ToTensorV2(p=1.0)\n",
    "],bbox_params = {'format':\"pascal_voc\",\"label_fields\":['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CeedDataset(train_data_df, str(DATAPATH / \"dataset\"),transform=train_transform)\n",
    "valid_data = CeedDataset(val_data_df, str(DATAPATH / \"dataset\"),transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,target = train_data.__getitem__(1)\n",
    "# plt.imshow(image)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 2\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total=0.0\n",
    "        self.iterations = 0.0\n",
    "    def send(self,value):\n",
    "        self.current_total+=value\n",
    "        self.iterations+=1\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0*self.current_total/self.iterations\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(valid_data,batch_size=BATCH_SIZE,shuffle=False,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "# val_loss = []\n",
    "model = model.to(DEVICE)\n",
    "params =[p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.Adam(params,lr=LR)\n",
    "loss_hist = Averager()\n",
    "itr = 1\n",
    "lr_scheduler=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = Averager()\n",
    "itr = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_hist.reset()\n",
    "    \n",
    "    for images, targets in train_dataloader:\n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "        print(\"GO\")\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        loss_hist.send(loss_value)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % 50 == 0:\n",
    "            print(f\"Iteration #{itr} loss: {loss_value}\")\n",
    "\n",
    "        itr += 1\n",
    "\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch #{epoch} loss: {loss_hist.value}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fasterrcnn_resnet50_fpn.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fc538f08547776375178536570d2d391fe5bfc2f7332b42ca0a2a1ee13da8a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
